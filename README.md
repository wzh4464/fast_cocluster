# Fast Co-clustering Library

A high-performance Rust library for bi-clustering (co-clustering) large matrices using SVD-based algorithms and flexible scoring methods.

## Table of Contents

- [Overview](#overview)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Input Data Format](#input-data-format)
- [Core Algorithms](#core-algorithms)
- [Scoring Methods](#scoring-methods)
- [Pipeline Configuration](#pipeline-configuration)
- [Usage Examples](#usage-examples)
- [Output Format](#output-format)
- [Performance](#performance)
- [API Reference](#api-reference)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)

## Overview

Fast Co-clustering finds coherent subgroups in data by simultaneously clustering rows and columns of a matrix. This is particularly useful for:

- **Gene expression analysis**: Finding co-expressed genes and sample groups
- **Recommendation systems**: Discovering user-item preference patterns
- **Market basket analysis**: Identifying product-customer segments
- **Document clustering**: Finding document-term associations
- **Social network analysis**: Detecting community structures

### Key Features

- **High Performance**: Parallel processing with Rayon
- **Flexible Algorithms**: SVD-based, spectral, and basic clustering
- **Multiple Scoring Methods**: Pearson correlation, exponential, compatibility scoring
- **Configurable Pipeline**: Easy-to-use builder pattern with sensible defaults
- **Memory Efficient**: Optimized for large matrices
- **Type Safe**: Full Rust type safety and error handling

## Installation

### Prerequisites

- Rust 1.70+ 
- BLAS/LAPACK libraries (for linear algebra operations)

### Add to Your Project

```toml
[dependencies]
fast_cocluster = { git = "https://github.com/wzh4464/fast_cocluster" }
nalgebra = "0.33"
ndarray = "0.15"
log = "0.4"
env_logger = "0.11"  # For logging (optional)
```

### System Dependencies

**Ubuntu/Debian:**
```bash
sudo apt-get install libblas-dev liblapack-dev
```

**macOS:**
```bash
brew install openblas lapack
```

**Windows:**
Install Intel MKL or OpenBLAS through vcpkg.

## Quick Start

```rust
use fast_cocluster::pipeline::*;
use fast_cocluster::scoring::*;
use fast_cocluster::Matrix;
use nalgebra::DMatrix;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging (optional)
    env_logger::init();
    
    // Create your data matrix (rows = samples, cols = features)
    let data = DMatrix::from_vec(100, 50, vec![/* your data */]);
    let matrix = Matrix::new(data.into());
    
    // Build and configure the pipeline
    let pipeline = CoclusterPipeline::builder()
        .with_clusterer(Box::new(SVDClusterer::new(5, 0.1)))
        .with_scorer(Box::new(PearsonScorer::new(3, 3)))
        .min_score(0.6)
        .max_submatrices(10)
        .build()?;
    
    // Run co-clustering
    let result = pipeline.run(&matrix)?;
    
    // Process results
    println!("Found {} co-clusters", result.submatrices.len());
    for (i, (submatrix, score)) in result.submatrices.iter()
        .zip(&result.scores).enumerate() {
        println!("Cluster {}: {}Ã—{} (score: {:.3})", 
                 i+1, 
                 submatrix.row_indices.len(), 
                 submatrix.col_indices.len(), 
                 score);
    }
    
    Ok(())
}
```

## Input Data Format

### Matrix Structure

The input should be a 2D matrix where:
- **Rows**: Observations/samples (e.g., genes, users, documents)
- **Columns**: Features/variables (e.g., conditions, items, terms)
- **Values**: Numeric data (f64)

### Supported Input Formats

#### 1. From Vec<f64>
```rust
use ndarray::Array2;
use fast_cocluster::Matrix;

let data_vec = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0];
let array = Array2::from_shape_vec((2, 3), data_vec)?;
let matrix = Matrix::new(array);
```

#### 2. From CSV File
```rust
use csv::Reader;
use std::fs::File;

fn load_from_csv(path: &str) -> Result<Matrix<f64>, Box<dyn std::error::Error>> {
    let file = File::open(path)?;
    let mut reader = Reader::from_reader(file);
    
    let mut data = Vec::new();
    let mut rows = 0;
    let mut cols = 0;
    
    for result in reader.records() {
        let record = result?;
        if rows == 0 {
            cols = record.len();
        }
        
        for field in record.iter() {
            data.push(field.parse::<f64>()?);
        }
        rows += 1;
    }
    
    let array = Array2::from_shape_vec((rows, cols), data)?;
    Ok(Matrix::new(array))
}
```

#### 3. From NumPy Arrays (.npy)
```rust
use ndarray_npy::ReadNpyExt;
use std::fs::File;

fn load_from_npy(path: &str) -> Result<Matrix<f64>, Box<dyn std::error::Error>> {
    let reader = File::open(path)?;
    let array: Array2<f64> = Array2::read_npy(reader)?;
    Ok(Matrix::new(array))
}
```

### Data Preprocessing Recommendations

```rust
// 1. Normalization (z-score)
fn normalize_matrix(matrix: &mut Array2<f64>) {
    let mean = matrix.mean().unwrap();
    let std = matrix.std(1.0);
    matrix.mapv_inplace(|x| (x - mean) / std);
}

// 2. Log transformation (for expression data)
fn log_transform(matrix: &mut Array2<f64>) {
    matrix.mapv_inplace(|x| (x + 1.0).ln());
}

// 3. Missing value handling
fn handle_missing_values(matrix: &mut Array2<f64>, fill_value: f64) {
    matrix.mapv_inplace(|x| if x.is_nan() { fill_value } else { x });
}
```

## ğŸ†• 3D å¼ é‡ Co-clustering (æ–°åŠŸèƒ½)

### Tucker åˆ†è§£é©±åŠ¨çš„3Då¼ é‡åˆ†æ

æœ¬é¡¹ç›®ç°å·²æ”¯æŒ3Då¼ é‡çš„co-clusteringåˆ†æï¼Œä½¿ç”¨Tuckeråˆ†è§£ç®—æ³•å®ç°é«˜æ•ˆçš„å¤šç»´æ•°æ®èšç±»ã€‚

#### å¿«é€Ÿå¼€å§‹ - 3Då¼ é‡

```rust
use fast_cocluster::tensor3d::*;
use fast_cocluster::tensor3d_scoring::*;
use fast_cocluster::tucker_decomposition::*;

// åˆ›å»º3Då¼ é‡ (ç”¨æˆ· Ã— ç‰©å“ Ã— ä¸Šä¸‹æ–‡)
let tensor = Tensor3D::random([100, 50, 20]);

// Tuckeråˆ†è§£
let tucker_rank = TuckerRank::new(5, 4, 3); // æŒ‡å®šæ¯ä¸ªæ¨¡å¼çš„rank
let decomposer = TuckerDecomposer::with_ranks(5, 4, 3);
let decomposition = decomposer.decompose(&tensor)?;

// å¼ é‡è¯„åˆ†
let scorer = TuckerScorer::new(tucker_rank);
let subspace = TensorSubspace::new(&tensor, vec![0,1,2], vec![0,1,2], vec![0,1,2]).unwrap();
let score = scorer.score(&tensor, &subspace);

println!("Tuckeråˆ†è§£é‡æ„è¯¯å·®: {:.4}", decomposition.reconstruction_error);
println!("å­ç©ºé—´è´¨é‡åˆ†æ•°: {:.4}", score);
```

#### æ”¯æŒçš„åº”ç”¨åœºæ™¯

- **åŸºå› è¡¨è¾¾åˆ†æ**: åŸºå›  Ã— æ¡ä»¶ Ã— æ—¶é—´ç‚¹
- **æ¨èç³»ç»Ÿ**: ç”¨æˆ· Ã— ç‰©å“ Ã— ä¸Šä¸‹æ–‡  
- **æ—¶ç©ºæ•°æ®**: ä¼ æ„Ÿå™¨ Ã— åœ°ç‚¹ Ã— æ—¶é—´
- **ç¤¾äº¤ç½‘ç»œ**: ç”¨æˆ· Ã— å†…å®¹ Ã— ç¤¾ç¾¤
- **é‡‘èåˆ†æ**: èµ„äº§ Ã— å› å­ Ã— æ—¶æœŸ

#### æ ¸å¿ƒç‰¹æ€§

- **Tuckeråˆ†è§£**: é«˜æ•ˆçš„3Då¼ é‡åˆ†è§£ç®—æ³•
- **å¤šç§è¯„åˆ†å™¨**: Tuckerã€å¯†åº¦ã€æ–¹å·®ã€ç»„åˆè¯„åˆ†
- **å¯é…ç½®Rank**: çµæ´»çš„Tucker ranké…ç½®
- **é«˜æ€§èƒ½**: å¹¶è¡Œè®¡ç®—å’Œå†…å­˜ä¼˜åŒ–
- **å®Œæ•´Pipeline**: ä»æ•°æ®åŠ è½½åˆ°ç»“æœè¾“å‡º

#### ä¸2D co-clusteringçš„å¯¹æ¯”

| ç‰¹æ€§ | 2DçŸ©é˜µ | 3Då¼ é‡ |
|------|--------|--------|
| ç®—æ³• | SVD + K-means | Tuckeråˆ†è§£ + èšç±» |
| æ•°æ®ç»“æ„ | Matrix<T> | Tensor3D<T> |
| åˆ†è§£æ–¹å¼ | å¥‡å¼‚å€¼åˆ†è§£ | Tuckeråˆ†è§£ |
| åº”ç”¨åœºæ™¯ | äºŒç»´å…³è”åˆ†æ | å¤šç»´å…³è”åˆ†æ |
| è®¡ç®—å¤æ‚åº¦ | O(mn min(m,n)) | O(Iâ‚Iâ‚‚Iâ‚ƒRâ‚Râ‚‚Râ‚ƒ) |

#### ç¤ºä¾‹ï¼šå®Œæ•´3Dåˆ†ææµç¨‹

```bash
# è¿è¡Œ3Då¼ é‡co-clusteringæ¼”ç¤º
cargo run --example tensor3d_complete_demo

# è¿è¡ŒåŸºç¡€3Då¼ é‡ç¤ºä¾‹
cargo run --example tensor3d_cocluster_example
```

## æ›¿æ¢åŸå­åŒ– Cocluster æ–¹æ³•

### ä»åŸå­åŒ–åˆ°æ¨¡å—åŒ–çš„è¿ç§»

åŸå§‹çš„ `Coclusterer::cocluster()` æ–¹æ³•æ˜¯ä¸€ä¸ªåŸå­åŒ–å®ç°ï¼Œå°†æ‰€æœ‰ç®—æ³•æ­¥éª¤ç¡¬ç¼–ç åœ¨ä¸€ä¸ªå‡½æ•°ä¸­ã€‚æ–°çš„æ¨¡å—åŒ–å®ç°æä¾›äº†æ›´å¥½çš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚

#### åŸå­åŒ–æ–¹æ³• (æ—§)
```rust
use fast_cocluster::cocluster::Coclusterer;

// åŸå­åŒ– - ä¸å¯å®šåˆ¶
let mut coclusterer = Coclusterer::new(matrix, 5, 0.1);
let result = coclusterer.cocluster()?; // å›ºå®š: SVD + K-means
```

#### æ¨¡å—åŒ–æ–¹æ³• (æ–°) - ç­‰æ•ˆæ›¿æ¢
```rust
use fast_cocluster::modular_cocluster::*;

// æ¨¡å—åŒ– - å®Œå…¨ç­‰æ•ˆäºåŸå­åŒ–æ–¹æ³•
let mut coclusterer = ModularCoclusterer::with_defaults(matrix, 5);
let result = coclusterer.cocluster()?;
```

#### æ¨¡å—åŒ–æ–¹æ³• - å¢å¼ºåŠŸèƒ½
```rust
// ä½¿ç”¨æ”¹è¿›çš„å½’ä¸€åŒ–
let mut coclusterer = ModularCoclusterer::with_zscore(matrix, 5);

// ä½¿ç”¨åŠ æƒç‰¹å¾ç»„åˆ
let mut coclusterer = ModularCoclusterer::with_weighted_features(matrix, 5, 0.8, 0.2);

// å®Œå…¨è‡ªå®šä¹‰ç»„ä»¶
let mut coclusterer = ModularCoclustererBuilder::new()
    .matrix(matrix)
    .k(5)
    .normalizer(Box::new(ZScoreNormalizer))
    .reducer(Box::new(SVDReducer))
    .combiner(Box::new(WeightedCombiner { row_weight: 0.7, col_weight: 0.3 }))
    .assigner(Box::new(KMeansAssigner))
    .build()?;
```

### è‡ªå®šä¹‰ç»„ä»¶ç¤ºä¾‹

```rust
// è‡ªå®šä¹‰å½’ä¸€åŒ–å™¨
struct MinMaxNormalizer;
impl MatrixNormalizer for MinMaxNormalizer {
    fn normalize(&self, matrix: &DMatrix<f64>) -> DMatrix<f64> {
        let min_val = matrix.min();
        let max_val = matrix.max();
        let range = max_val - min_val;
        if range > 0.0 {
            matrix.map(|x| (x - min_val) / range)
        } else {
            matrix.clone()
        }
    }
}

// ä½¿ç”¨è‡ªå®šä¹‰ç»„ä»¶
let mut coclusterer = ModularCoclustererBuilder::new()
    .matrix(matrix)
    .k(5)
    .normalizer(Box::new(MinMaxNormalizer))
    .build()?;
```

### æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | æ‰§è¡Œæ—¶é—´ | ä¼˜åŠ¿ | é™åˆ¶ |
|------|----------|------|------|
| åŸå­åŒ– | 105ms | ç®€å•ç›´æ¥ | ä¸å¯å®šåˆ¶ã€ä¸å¯æ‰©å±• |
| æ¨¡å—åŒ–é»˜è®¤ | 76ms | ç­‰æ•ˆåŠŸèƒ½ + å¯æ‰©å±• | æ—  |
| æ¨¡å—åŒ–è‡ªå®šä¹‰ | 75ms | å®Œå…¨å¯å®šåˆ¶ | éœ€è¦ç†è§£ç»„ä»¶æ¥å£ |

## Core Algorithms

### 1. SVD Clusterer (Recommended)

Uses Singular Value Decomposition for dimensionality reduction followed by k-means clustering.

```rust
let clusterer = SVDClusterer::new(
    5,    // Number of clusters
    0.1   // Convergence tolerance
);
```

**Best for**: General-purpose co-clustering, works well with most data types.

**Advantages**: 
- Fast and memory-efficient
- Handles noise well
- Good for large matrices

### 2. Spectral Co-clusterer

Advanced spectral clustering approach for non-linear patterns.

```rust
let clusterer = SpectralCoclustererHook::new(
    SpectralCoclustererParams {
        n_clusters: 5,
        n_svd_vectors: Some(10),
        max_svd_features: Some(100),
    }
);
```

**Best for**: Complex, non-linear patterns in data.

### 3. Basic Co-clusterer

Simple partitioning approach for quick results.

```rust
let clusterer = BasicCoclusterer::new(
    BasicCoclustererParams {
        n_clusters: 3,
    }
);
```

**Best for**: Quick prototyping, simple datasets.

## Scoring Methods

### 1. Pearson Correlation Scorer

Measures linear correlation within co-clusters.

```rust
let scorer = PearsonScorer::new(
    3,  // Minimum rows
    3   // Minimum columns
);
```

**Range**: [-1, 1] (higher is better)  
**Best for**: Linear relationships, gene expression data

### 2. Exponential Scorer

Emphasizes tight clustering with exponential decay.

```rust
let scorer = ExponentialScorer::new(1.5); // Decay parameter
```

**Range**: [0, âˆ) (higher is better)  
**Best for**: Compact, well-defined clusters

### 3. Compatibility Scorer

Measures variance-based cluster quality.

```rust
let scorer = CompatibilityScorer::new(
    0.5,  // Row weight
    0.5   // Column weight
);
```

**Range**: [0, 1] (higher is better)  
**Best for**: Balanced row-column clustering

### 4. Composite Scorer

Combines multiple scoring methods with weights.

```rust
let scorer = CompositeScorer::new()
    .add_scorer(Box::new(PearsonScorer::new(3, 3)), 0.6)
    .add_scorer(Box::new(ExponentialScorer::new(1.0)), 0.3)
    .add_scorer(Box::new(CompatibilityScorer::new(0.5, 0.5)), 0.1);
```

## Pipeline Configuration

### Basic Configuration

```rust
let config = PipelineConfig {
    min_score: 0.5,              // Minimum score threshold
    max_submatrices: 50,         // Maximum number of results
    sort_by_score: true,         // Sort results by score
    min_submatrix_size: (3, 3),  // Minimum size (rows, cols)
    collect_stats: true,         // Collect performance statistics
    parallel: true,              // Enable parallel processing
};
```

### Advanced Configuration

```rust
let pipeline = CoclusterPipeline::builder()
    .with_clusterer(Box::new(SVDClusterer::new(8, 0.1)))
    .with_scorer(Box::new(composite_scorer))
    .min_score(0.7)
    .max_submatrices(20)
    .min_submatrix_size(5, 5)
    .parallel(true)
    .build()?;
```

## Usage Examples

### Example 1: Gene Expression Analysis

```rust
use fast_cocluster::*;
use nalgebra::DMatrix;

fn analyze_gene_expression() -> Result<(), Box<dyn std::error::Error>> {
    // Load gene expression matrix (genes Ã— samples)
    let expression_data = load_expression_data("expression.csv")?;
    
    // Configure for biological data
    let pipeline = CoclusterPipeline::builder()
        .with_clusterer(Box::new(SVDClusterer::new(6, 0.1)))
        .with_scorer(Box::new(PearsonScorer::new(5, 3)))
        .min_score(0.7)
        .max_submatrices(15)
        .min_submatrix_size(10, 5)  // At least 10 genes, 5 samples
        .build()?;
    
    let result = pipeline.run(&expression_data)?;
    
    // Find co-expressed gene modules
    for (i, (submatrix, score)) in result.submatrices.iter()
        .zip(&result.scores).enumerate() {
        println!("Gene module {}: {} genes Ã— {} samples (r={:.3})", 
                 i+1, 
                 submatrix.row_indices.len(), 
                 submatrix.col_indices.len(), 
                 score);
        
        // Get gene and sample indices
        println!("Genes: {:?}", &submatrix.row_indices[..5.min(submatrix.row_indices.len())]);
        println!("Samples: {:?}", &submatrix.col_indices);
    }
    
    Ok(())
}
```

### Example 2: Recommendation System

```rust
fn analyze_user_item_preferences() -> Result<(), Box<dyn std::error::Error>> {
    // Load user-item rating matrix
    let ratings = load_ratings_matrix("ratings.csv")?;
    
    // Configure for recommendation data
    let pipeline = CoclusterPipeline::builder()
        .with_clusterer(Box::new(SVDClusterer::new(10, 0.05)))
        .with_scorer(Box::new(CompatibilityScorer::new(0.6, 0.4)))
        .min_score(0.6)
        .max_submatrices(25)
        .min_submatrix_size(5, 3)  // At least 5 users, 3 items
        .build()?;
    
    let result = pipeline.run(&ratings)?;
    
    // Analyze user-item co-clusters
    for (i, (submatrix, score)) in result.submatrices.iter()
        .zip(&result.scores).enumerate() {
        println!("User-Item cluster {}: {} users Ã— {} items (score={:.3})", 
                 i+1, 
                 submatrix.row_indices.len(), 
                 submatrix.col_indices.len(), 
                 score);
    }
    
    Ok(())
}
```

### Example 3: Time Series Co-clustering

```rust
fn analyze_time_series() -> Result<(), Box<dyn std::error::Error>> {
    // Load time series matrix (sensors Ã— time points)
    let time_series = load_time_series("sensors.csv")?;
    
    // Use exponential scorer for tight temporal patterns
    let scorer = CompositeScorer::new()
        .add_scorer(Box::new(ExponentialScorer::new(2.0)), 0.7)
        .add_scorer(Box::new(PearsonScorer::new(3, 3)), 0.3);
    
    let pipeline = CoclusterPipeline::builder()
        .with_clusterer(Box::new(SVDClusterer::new(5, 0.1)))
        .with_scorer(Box::new(scorer))
        .min_score(0.8)
        .max_submatrices(10)
        .build()?;
    
    let result = pipeline.run(&time_series)?;
    
    // Analyze temporal patterns
    for (i, (submatrix, score)) in result.submatrices.iter()
        .zip(&result.scores).enumerate() {
        println!("Pattern {}: {} sensors Ã— {} time points (score={:.3})", 
                 i+1, 
                 submatrix.row_indices.len(), 
                 submatrix.col_indices.len(), 
                 score);
    }
    
    Ok(())
}
```

## Output Format

### StepResult Structure

```rust
pub struct StepResult<'a> {
    pub submatrices: Vec<Submatrix<'a, f64>>,  // Found co-clusters
    pub scores: Vec<f64>,                       // Corresponding scores
    pub stats: Option<PipelineStats>,           // Performance statistics
}
```

### Submatrix Structure

```rust
pub struct Submatrix<'a, T> {
    pub row_indices: Vec<usize>,    // Row indices in original matrix
    pub col_indices: Vec<usize>,    // Column indices in original matrix
    // Internal data view...
}
```

### Accessing Results

```rust
let result = pipeline.run(&matrix)?;

// Iterate through co-clusters
for (i, (submatrix, score)) in result.submatrices.iter()
    .zip(&result.scores).enumerate() {
    
    // Get dimensions
    let n_rows = submatrix.row_indices.len();
    let n_cols = submatrix.col_indices.len();
    
    // Access specific elements
    let first_row = submatrix.row_indices[0];
    let first_col = submatrix.col_indices[0];
    
    // Get the actual data values
    let data_value = matrix.data[(first_row, first_col)];
    
    println!("Cluster {}: {}Ã—{} (score: {:.3})", i+1, n_rows, n_cols, score);
}
```

### Exporting Results

```rust
use std::fs::File;
use std::io::Write;

fn export_results(result: &StepResult, filename: &str) -> std::io::Result<()> {
    let mut file = File::create(filename)?;
    
    writeln!(file, "cluster_id,score,n_rows,n_cols,row_indices,col_indices")?;
    
    for (i, (submatrix, score)) in result.submatrices.iter()
        .zip(&result.scores).enumerate() {
        
        let row_str = submatrix.row_indices.iter()
            .map(|x| x.to_string())
            .collect::<Vec<_>>()
            .join(";");
            
        let col_str = submatrix.col_indices.iter()
            .map(|x| x.to_string())
            .collect::<Vec<_>>()
            .join(";");
        
        writeln!(file, "{},{:.4},{},{},\"{}\",\"{}\"", 
                 i+1, score, 
                 submatrix.row_indices.len(), 
                 submatrix.col_indices.len(),
                 row_str, col_str)?;
    }
    
    Ok(())
}
```

## Performance

### Benchmarks

**Dataset**: 1000Ã—500 random matrix  
**Hardware**: Intel i7-8750H, 16GB RAM

| Algorithm | Clusters | Time | Memory |
| --------- | -------- | ---- | ------ |
| SVD       | 5        | 1.2s | 45MB   |
| SVD       | 10       | 2.1s | 52MB   |
| Basic     | 5        | 0.3s | 25MB   |
| Spectral  | 5        | 3.8s | 85MB   |

### Optimization Guidelines

#### 1. Choose Appropriate Parameters

```rust
// For large matrices (>1000Ã—1000)
let pipeline = CoclusterPipeline::builder()
    .with_clusterer(Box::new(SVDClusterer::new(5, 0.1)))  // Fewer clusters
    .max_submatrices(20)    // Limit results
    .min_submatrix_size(10, 10)  // Larger minimum size
    .parallel(true)         // Enable parallelism
    .build()?;
```

#### 2. Memory Management

```rust
// Process in batches for very large datasets
fn process_large_matrix(matrix: &Array2<f64>) -> Result<Vec<StepResult>, Box<dyn std::error::Error>> {
    let chunk_size = 1000;
    let mut results = Vec::new();
    
    for chunk in matrix.axis_chunks_iter(Axis(0), chunk_size) {
        let chunk_matrix = Matrix::new(chunk.to_owned());
        let result = pipeline.run(&chunk_matrix)?;
        results.push(result);
    }
    
    Ok(results)
}
```

#### 3. Parallel Processing

```rust
// Set number of threads
std::env::set_var("RAYON_NUM_THREADS", "8");

// Enable parallel scoring
let config = PipelineConfig {
    parallel: true,
    // ... other settings
};
```

## API Reference

### Core Types

- `Matrix<T>`: Wrapper around ndarray::Array2<T>
- `Submatrix<'a, T>`: View into a matrix with row/column indices
- `CoclusterPipeline`: Main pipeline for co-clustering
- `PipelineConfig`: Configuration structure

### Clusterer Trait

```rust
pub trait Clusterer: Send + Sync {
    fn cluster<'matrix_life>(
        &self,
        matrix: &'matrix_life Matrix<f64>
    ) -> Result<Vec<Submatrix<'matrix_life, f64>>, Box<dyn Error>>;
    
    fn name(&self) -> &str;
}
```

### Scorer Trait

```rust
pub trait Scorer: Send + Sync {
    fn score(&self, matrix: &Matrix<f64>, submatrix: &Submatrix<f64>) -> f64;
    fn score_all(&self, matrix: &Matrix<f64>, submatrices: &[Submatrix<f64>]) -> Vec<f64>;
}
```

### Builder Pattern

```rust
impl PipelineBuilder {
    pub fn new() -> Self;
    pub fn with_clusterer(self, clusterer: Box<dyn Clusterer>) -> Self;
    pub fn with_scorer(self, scorer: Box<dyn Scorer>) -> Self;
    pub fn min_score(self, min_score: f64) -> Self;
    pub fn max_submatrices(self, max: usize) -> Self;
    pub fn min_submatrix_size(self, rows: usize, cols: usize) -> Self;
    pub fn parallel(self, parallel: bool) -> Self;
    pub fn build(self) -> Result<CoclusterPipeline, &'static str>;
}
```

## Troubleshooting

### Common Issues

#### 1. "SVD did not converge"

**Cause**: Matrix has numerical issues or is rank-deficient.

**Solutions**:
- Increase tolerance: `SVDClusterer::new(k, 0.2)`
- Preprocess data: normalize or add small noise
- Check for NaN/infinite values

```rust
// Check for problematic values
fn validate_matrix(matrix: &Array2<f64>) -> Result<(), &'static str> {
    if matrix.iter().any(|&x| x.is_nan() || x.is_infinite()) {
        return Err("Matrix contains NaN or infinite values");
    }
    Ok(())
}
```

#### 2. "No co-clusters found"

**Cause**: Parameters too restrictive or data doesn't have clear structure.

**Solutions**:
- Lower `min_score` threshold
- Reduce `min_submatrix_size`
- Try different scoring methods
- Increase number of clusters

```rust
// More permissive configuration
let pipeline = CoclusterPipeline::builder()
    .min_score(0.3)              // Lower threshold
    .min_submatrix_size(2, 2)    // Smaller minimum size
    .max_submatrices(100)        // More results
    .build()?;
```

#### 3. "Out of memory"

**Cause**: Matrix too large for available memory.

**Solutions**:
- Process in chunks
- Use dimensionality reduction first
- Increase virtual memory
- Use streaming algorithms

```rust
// Chunked processing
fn process_in_chunks(matrix: &Array2<f64>, chunk_size: usize) 
    -> Result<Vec<StepResult>, Box<dyn std::error::Error>> {
    // Implementation above
}
```

#### 4. "Poor clustering quality"

**Cause**: Inappropriate algorithm or parameters for data type.

**Solutions**:
- Try different clustering algorithms
- Experiment with scoring methods
- Preprocess data (normalization, log transform)
- Adjust number of clusters

```rust
// Try multiple configurations
let algorithms = vec![
    SVDClusterer::new(5, 0.1),
    SVDClusterer::new(10, 0.05),
    // Add more variants
];

for clusterer in algorithms {
    let result = pipeline_with_clusterer(clusterer).run(&matrix)?;
    evaluate_quality(&result);
}
```

### Debug Tips

#### Enable Detailed Logging

```rust
env_logger::Builder::from_default_env()
    .filter_level(log::LevelFilter::Debug)
    .init();
```

#### Collect Statistics

```rust
let config = PipelineConfig {
    collect_stats: true,
    // ... other settings
};

// Access statistics
if let Some(stats) = &result.stats {
    println!("Total time: {:?}", stats.total_duration);
    println!("Clustering time: {:?}", stats.clustering_duration);
    println!("Scoring time: {:?}", stats.scoring_duration);
    println!("Score distribution: {:.3} Â± {:.3}", 
             stats.score_distribution.mean,
             stats.score_distribution.std_dev);
}
```

#### Visualize Results

```rust
// Simple visualization function
fn print_cluster_matrix(matrix: &Array2<f64>, submatrix: &Submatrix<f64>) {
    println!("Cluster data (first 5Ã—5):");
    for (i, &row_idx) in submatrix.row_indices.iter().take(5).enumerate() {
        for (j, &col_idx) in submatrix.col_indices.iter().take(5).enumerate() {
            print!("{:6.2} ", matrix[(row_idx, col_idx)]);
        }
        println!();
    }
}
```

### Performance Issues

#### Slow Performance

1. **Enable parallel processing**: Set `parallel: true`
2. **Reduce precision**: Increase tolerance values
3. **Limit results**: Reduce `max_submatrices`
4. **Use appropriate algorithm**: SVD for general use, Basic for quick results

#### High Memory Usage

1. **Limit cluster count**: Reduce number of clusters
2. **Disable statistics**: Set `collect_stats: false`
3. **Process in batches**: Split large matrices
4. **Use views instead of copies**: Ensure efficient memory usage

## Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup

```bash
git clone https://github.com/wzh4464/fast_cocluster
cd fast_cocluster
cargo build
cargo test
```

### Running Benchmarks

```bash
cargo bench
```

### Adding New Algorithms

Implement the `Clusterer` trait:

```rust
pub struct MyClusterer {
    // parameters
}

impl Clusterer for MyClusterer {
    fn cluster<'matrix_life>(
        &self,
        matrix: &'matrix_life Matrix<f64>
    ) -> Result<Vec<Submatrix<'matrix_life, f64>>, Box<dyn Error>> {
        // Implementation
    }
    
    fn name(&self) -> &str {
        "MyClusterer"
    }
}
```

### Adding New Scoring Methods

Implement the `Scorer` trait:

```rust
pub struct MyScorer {
    // parameters
}

impl Scorer for MyScorer {
    fn score(&self, matrix: &Matrix<f64>, submatrix: &Submatrix<f64>) -> f64 {
        // Implementation
    }
}
```

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Citation

If you use this library in your research, please cite:

```bibtex
@inproceedings{wu2024ScalableCoclusteringLargescale,
  title = {Scalable Co-Clustering for Large-Scale Data through Dynamic Partitioning and Hierarchical Merging},
  booktitle = {2024 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Wu, Zihan and Huang, Zhaoke and Yan, Hong},
  year = {2024},
  month = oct,
  pages = {4686--4691},
  publisher = {IEEE},
  address = {Kuching, Malaysia},
  doi = {10.1109/SMC54092.2024.10832071},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-1-6654-1020-5},
}
```
